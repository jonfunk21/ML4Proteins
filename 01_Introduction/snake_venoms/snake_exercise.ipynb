{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEbevSBv---4"
   },
   "source": [
    "# Snake venom classification exercise\n",
    "\n",
    "In this exercise, we are going to take a look at snake venoms :snake:. Because this is an educational course, we are first going\n",
    "to examine how we can use vsiualizations and basic machine learning libraries, such as scikit-learn to classify the snake venoms.\n",
    "Later we are going to use ProteusAI to greatly simplify the workflow and to add additional capabilities.\n",
    "\n",
    "We will use the UniProt database to fetch snake venom toxin sequences. We will use a custom query to select reviewed snake toxin entries.\n",
    "\n",
    "**UniProt Query**: `taxonomy_id:8570 AND ( cc_tissue_specificity:venom OR cc_scl_term:SL-0177) AND reviewed:true`\n",
    "\n",
    "We filtered the data, removing toxins that are hard to group into categories and assigned Function Classes based on the 'Function [CC]' column\n",
    "using OpenAIs GPT o1 model. This was done to create simple functional labels that we can more easily work with, instead of the lengthy function descriptions.\n",
    "\n",
    "Pandas is imported to load the data and Matplotlib is used to visualize it. Take a look at the data columns.\n",
    "\n",
    "_The exercises have been created by Jonathan Funk and Valentas Brasas_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "p-E0EqgG---5",
    "outputId": "1b22feb4-d4d5-48f6-ef42-6ac15904b362"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Snake_Toxins_with_Function_Classes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvmyS8uxJCit"
   },
   "source": [
    "### Exercise 1: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Objective: Familiarizing with the dataset and understanding the distribution of different toxin functional classes to identify any class imbalances that might affect model performance.\n",
    "\n",
    "\n",
    "1. Count the Number of Instances per Class\n",
    "2. Check if there are any missing, duplicate or inconsistent data to ensure data quality for model training.\n",
    "3. Analyze the distribution of protein sequence lengths to understand variability and inform preprocessing steps like padding or truncation.\n",
    "4. Examine the frequency and distribution of each amino acid in the protein sequences to identify patterns or biases that could inform feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbsFnYkiJB9R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uI6vClru---5"
   },
   "source": [
    "## Visualizing protein sequences\n",
    "\n",
    "In machine learning data is represented numerically, frequently in the form of vectors. There are countless different choices to be made\n",
    "when representing proteins as vectors, which will be covered in detail in later lectures. Here we are going to start simply by encoding\n",
    "sequences as one-hot encoded vectors. This means, that we are going to assign each residue in the sequence with a vector, that is\n",
    "0 in every position except for a single 1. The position of the one will indicate which amino acid we are dealing with.\n",
    "\n",
    "For example, the amino acid Alanine (Ala, A) can be represented as having the 1 in the first position, while the amino acid\n",
    "Cystein (Cys, C) can be represented as having the 1 in the second position. Thus, we will communicate that the two amino acids\n",
    "are different entities. This method of encoding is known as One-Hot Encoding, or short OHE and commonly used to represent discrete\n",
    "sequences.\n",
    "\n",
    "Note, that the only information the machine learning algorithms will have when using this annotation is, that\n",
    "the amino acids are different.\n",
    "\n",
    "### Ecercise 2 : What could be a problem when representing amino acids as:\n",
    "\n",
    "    1. A=1, C=2, D=3, ..., Y=20?\n",
    "    \n",
    "    2. Using OHE\n",
    "\n",
    "We will use numpy to encode the protein sequences as vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0TGJtJX---5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def one_hot_encode(seq):\n",
    "    # Dictionary of standard amino acids\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    aa_to_int = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "\n",
    "    # Initialize the one-hot encoded matrix\n",
    "    one_hot = np.zeros((len(seq), len(amino_acids)), dtype=int)\n",
    "\n",
    "    # Fill the matrix\n",
    "    for i, aa in enumerate(seq):\n",
    "        if aa in aa_to_int:\n",
    "            one_hot[i, aa_to_int[aa]] = 1\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "wmcrpkeb---6",
    "outputId": "6fd8c873-fa96-4a7b-be30-7384c37da0ca"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def visualize_one_hot(encoded_seq, seq):\n",
    "    # Create a heatmap from the one-hot encoded matrix\n",
    "    plt.figure(figsize=(10, len(encoded_seq) / 2))\n",
    "    sns.heatmap(\n",
    "        encoded_seq,\n",
    "        annot=True,\n",
    "        cbar=False,\n",
    "        cmap=\"rocket\",\n",
    "        xticklabels=list(\"ACDEFGHIKLMNPQRSTVWY\"),\n",
    "        yticklabels=list(seq),\n",
    "    )\n",
    "    plt.xlabel(\"Amino Acids\")\n",
    "    plt.ylabel(\"Sequence Position\")\n",
    "    plt.title(\"One-Hot Encoding of Amino Acid Sequence\")\n",
    "    plt.savefig(\"one_hot_encoding.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "seq = \"MLQVLLVTICLAVF\"\n",
    "encoded_seq = one_hot_encode(seq)\n",
    "visualize_one_hot(encoded_seq, seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi7JzdBBMAJ5"
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "1. What are different ways to encode protein sequences for machine learning algorithms? List at least 4 of them (One Hot Encoding).\n",
    "\n",
    "| Encoding Method | Description | Advantages | Disadvantages |\n",
    "|-----------------|-----------------|-----------------|-----------------|\n",
    "| _One hot encoding_   | _Description 1_   | _List the advantages for Encoding 1 ._     |_List the disadvantages for Encoding 1 ._     |\n",
    "| _Method 2_    | _Description 2_    | _List the advantages for Encoding 2 ._    |_List the disadvantages for Encoding 2 ._      |\n",
    "| _Method 3_    | _Description 3_    | _List the advantages for Encoding 3 ._     |_List the disadvantages for Encoding 3 ._    |\n",
    "| _Method 4_    | _Description 4_    | _List the advantages for Encoding 4 ._    |_List the disadvantages for Encoding 4 ._   |\n",
    "\n",
    "2. Write functions to encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm2S5Gc6---6"
   },
   "source": [
    "### Now let's encode the entire df\n",
    "\n",
    "In machine learning it is common to call the input x, thus we are encoding the sequences and give the column the name x.\n",
    "\n",
    "### Exercise 4:\n",
    "\n",
    "Create a column 'x' in the dataframe to encode all protein sequences using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "5RdlYyIC---6",
    "outputId": "316f4772-3dcb-45bf-c989-5dadc85be8d5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSQc2t-Q---6"
   },
   "source": [
    "## Encoding class labels\n",
    "\n",
    "Next we also need to encode the class labels. These are also going to be encoded using OHe, however, the library we are going to use expects train the classification model\n",
    "expects simple numbers as class labels and does the OHE under the hood. Because of this we are going to encode the classes as numbers. The output variable (class in this case),\n",
    "is often called y. Thus we are calling the encoded class labels y.\n",
    "\n",
    "### Exercise 5:\n",
    "\n",
    "Create a column 'y' in the dataframe, assigning unique integer values to individual function classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "n7mj3CAy---6",
    "outputId": "b49d0fa5-ba43-4a60-9cf7-ae5969b22988"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyXB_8Mr---6"
   },
   "source": [
    "## Training the classification model using scikit-learn\n",
    "\n",
    "Next, we are going to train machine learning models using scikit-learn to classify snake toxins based on.\n",
    "\n",
    "### Exercise 6:\n",
    "\n",
    "    3.1 Load the dataset into variables X (features) and y (labels).\n",
    "    3.2 Explore the structure of X. Are all sequences in X the same size? If not, figure out how to handle this.\n",
    "    3.3 Divide the dataset into training and testing sets.\n",
    "    3.4 Pick a classifier from the following options:\n",
    "        a. Logistic Regression\n",
    "        b. Random Forest\n",
    "        c. Support Vector Machine\n",
    "    3.5 Make predictions\n",
    "    3.6 Evaluate the model with appropriate metrics and interpret the results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtCGwP8u---6",
    "outputId": "cef9a303-0850-4e2f-9bc7-09eb03bff386"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1pWLOoh---7"
   },
   "source": [
    "## Visualizing results\n",
    "\n",
    "Now that we have trained the model we would like to visualize the results, which is an important step to communicate the capabilities of your model, but its also interesting for you to quickly see where your model performs better or worse. Visualize your results using a confusion matrix.\n",
    "\n",
    "### Exercise 7\n",
    "\n",
    "    4.1 Visualize the classification results using a confusion matrix. \n",
    "    4.2 Discuss the results? What are the differences between the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 895
    },
    "id": "SKTTcDur---7",
    "outputId": "5be4001b-cd0d-4207-cdcc-7dbf779da319"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8SP5EnuOF-d"
   },
   "source": [
    "### Exercise 8\n",
    "\n",
    "1. Compare Metrics: Write a code to analyze and compare how different classification metrics (precision, recall, F1-score) correlate with each other.\n",
    "\n",
    "2. Add a New Metric: Implement an additional metric (e.g., ROC-AUC, Matthews Correlation Coefficient) and use it to further compare the models.\n",
    "\n",
    "3. Model Comparison: Re-run three classification models—Logistic Regression, Random Forest, and Support Vector Machine (SVM). Compare their performance using the metrics above and determine which model performs best.\n",
    "\n",
    "4. Optimize Model Performance: Explore and apply new strategies to improve classification results. Potential strategies to try:\n",
    "   * Experiment with different sequence encoding methods (e.g., k-mer encoding, * physicochemical properties).\n",
    "   * Address class imbalance using techniques like oversampling, undersampling, or adjusting class weights.\n",
    "   * Implement an ensemble method, such as a voting classifier or boosting, to combine the strengths of multiple models.\n",
    "   * Perform hyperparameter tuning using GridSearchCV, RandomizedSearchCV, or Bayesian optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2StINmz---7"
   },
   "source": [
    "# ProteusAI\n",
    "\n",
    "Now lets do the same thing with the library ´ProteusAI´ which automates a lot of the tideous steps and gets you from training to results in only a few lines of code. ProteusAI will be used in later exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "n2WzZKQw---7",
    "outputId": "d59aaad9-93b6-49b2-bee2-b8cbf5371ef7"
   },
   "outputs": [],
   "source": [
    "import proteusAI as pai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpL0h5xB---7"
   },
   "outputs": [],
   "source": [
    "lib = pai.Library(\n",
    "    source=\"Snake_Toxins_with_Function_Classes.csv\",\n",
    "    names_col=\"Entry Name\",\n",
    "    seqs_col=\"Sequence\",\n",
    "    y_col=\"Function Class\",\n",
    "    y_type=\"class\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ddzjuvt---7"
   },
   "outputs": [],
   "source": [
    "lib.compute(\"esm2_8M\", device=\"cpu\", batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xG4C5qo7---7"
   },
   "outputs": [],
   "source": [
    "fig, ax, df = lib.plot(method=\"tsne\", rep=\"esm2_8M\")\n",
    "\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2, 1.0))\n",
    "plt.savefig(\"tsne.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jY-Cy1Cq---7"
   },
   "outputs": [],
   "source": [
    "fig, ax, df = lib.plot(method=\"tsne\", rep=\"esm2_8M\")\n",
    "\n",
    "plt.savefig(\"tsne.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgUjJ8v1---8"
   },
   "outputs": [],
   "source": [
    "model = pai.Model(\n",
    "    model_type=\"rf\",\n",
    "    library=lib,\n",
    "    x=\"esm2_8M\",\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZQ6e5OG---8"
   },
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-PogPZv---8"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix (implement in ProteusAI)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "pi7JzdBBMAJ5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "proteusAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
