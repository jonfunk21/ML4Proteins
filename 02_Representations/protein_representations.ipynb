{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d41c01a",
   "metadata": {},
   "source": [
    "# Protein representations\n",
    "\n",
    "In this notebook you are going to learn more about different methods to encode proteins as vectors. \n",
    "First we are going to take a look at basic encoding methods, followed by the training of latent variable models.\n",
    "\n",
    "The focus of this notebook is to give you some more intuition on how different representations introduce inductive biases into sequences.\n",
    "We will learn how similar different residues are to each other when using different representations and also how we can use representations to train machine learning models. \n",
    "\n",
    "Finally, we will train Autoencoder models using a classical representation of your choice, based on inspiration from the Autoencoders notebook. We will analyze the representation spaces generated by our autoencoders and compare the generative abilities of a regular autoencoder with a variational autoencoder trained on protein sequences.\n",
    "\n",
    "Once we have analyzed the representation space we can build a classification model using our representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99e15d-1747-4ee1-bb6c-0f5f2b701964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../01_Introduction/snake_venoms/Snake_Toxins_with_Function_Classes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b324e8fe",
   "metadata": {},
   "source": [
    "## Classical representations\n",
    "\n",
    "In the lecture we covered classical representations starting with one hot encoding (OHE), Vectors of Hydrophobic, Steric, and Electronic properties (VSHE) encodings, and BLOcks SUbstitution Matrix (BLOSUM) encodings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096809a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the VHSE dictionary\n",
    "vhse_dict = {\n",
    "    \"A\": [0.15, -1.11, -1.35, -0.92, 0.02, -0.91, 0.36, -0.48],\n",
    "    \"R\": [-1.47, 1.45, 1.24, 1.27, 1.55, 1.47, 1.30, 0.83],\n",
    "    \"N\": [-0.99, 0.00, -0.37, 0.69, -0.55, 0.85, 0.73, -0.80],\n",
    "    \"D\": [-1.15, 0.67, -0.41, -0.01, -2.68, 1.31, 0.03, 0.56],\n",
    "    \"C\": [0.18, -1.67, -0.46, -0.21, 0.00, 1.20, -1.61, -0.19],\n",
    "    \"Q\": [-0.96, 0.12, 0.18, 0.16, 0.09, 0.42, -0.20, -0.41],\n",
    "    \"E\": [-1.18, 0.40, 0.10, 0.36, -2.16, -0.17, 0.91, 0.02],\n",
    "    \"G\": [-0.20, -1.53, -2.63, 2.28, -0.53, -1.18, 2.01, -1.34],\n",
    "    \"H\": [-0.43, -0.25, 0.37, 0.19, 0.51, 1.28, 0.93, 0.65],\n",
    "    \"I\": [1.27, -0.14, 0.30, -1.80, 0.30, -1.61, -0.16, -0.13],\n",
    "    \"L\": [1.36, 0.07, 0.26, -0.80, 0.22, -1.37, 0.08, -0.62],\n",
    "    \"K\": [-1.17, 0.70, 0.70, 0.80, 1.64, 0.67, 1.63, 0.13],\n",
    "    \"M\": [1.01, -0.53, 0.43, 0.00, 0.23, 0.10, -0.86, -0.68],\n",
    "    \"F\": [1.52, 0.61, 0.96, -0.16, 0.25, 0.28, -1.33, -0.20],\n",
    "    \"P\": [0.22, -0.17, -0.50, 0.05, -0.01, -1.34, -0.19, 3.56],\n",
    "    \"S\": [-0.67, -0.86, -1.07, -0.41, -0.32, 0.27, -0.64, 0.11],\n",
    "    \"T\": [-0.34, -0.51, -0.55, -1.06, -0.06, -0.01, -0.79, 0.39],\n",
    "    \"W\": [1.50, 2.06, 1.79, 0.75, 0.75, -0.13, -1.01, -0.85],\n",
    "    \"Y\": [0.61, 1.60, 1.17, 0.73, 0.53, 0.25, -0.96, -0.52],\n",
    "    \"V\": [0.76, -0.92, -0.17, -1.91, 0.22, -1.40, -0.24, -0.03]\n",
    "}\n",
    "\n",
    "def vhse_encoder(sequences):\n",
    "    \"\"\"\n",
    "    Encodes sequences using VHSE descriptors.\n",
    "\n",
    "    Parameters:\n",
    "        sequences (list or str): List of amino acid sequences or a single sequence.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: VHSE encoded tensor of shape\n",
    "                      (number of sequences, padding or max sequence length, 8)\n",
    "    \"\"\"\n",
    "    # Ensure input is a list\n",
    "    if isinstance(sequences, str):\n",
    "        singular = True\n",
    "        sequences = [sequences]\n",
    "    else:\n",
    "        singular = False\n",
    "\n",
    "    # Determine maximum sequence length and apply padding\n",
    "    max_sequence_length = max(len(sequence) for sequence in sequences)\n",
    "    padded_length = max_sequence_length\n",
    "\n",
    "    n_sequences = len(sequences)\n",
    "    vhse_size = 8  # VHSE descriptors have 8 components\n",
    "\n",
    "    # Initialize output tensor with zeros\n",
    "    tensor = torch.zeros((n_sequences, padded_length, vhse_size))\n",
    "\n",
    "    # Encode each sequence\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j, aa in enumerate(sequence):\n",
    "            if j >= padded_length:\n",
    "                break\n",
    "            tensor[i, j] = torch.tensor(vhse_dict.get(aa, [0.5] * vhse_size))  # Default for unknown AAs\n",
    "\n",
    "    # Squeeze output for single sequence input\n",
    "    if singular:\n",
    "        tensor = tensor.squeeze(0)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def one_hot_encode(seq):\n",
    "    # Dictionary of standard amino acids\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    aa_to_int = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "\n",
    "    # Initialize the one-hot encoded matrix\n",
    "    one_hot = torch.zeros((len(seq), len(amino_acids)))\n",
    "\n",
    "    # Fill the matrix\n",
    "    for i, aa in enumerate(seq):\n",
    "        if aa in aa_to_int:\n",
    "            one_hot[i, aa_to_int[aa]] = 1\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "def blosum_62_encoder(sequences):\n",
    "    \"\"\"\n",
    "    Encodes sequences using BLOSUM62 matrix.\n",
    "\n",
    "    Parameters:\n",
    "        sequences (list or str): List of amino acid sequences or a single sequence.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: BLOSUM62 encoded tensor of shape\n",
    "                      (number of sequences, padding or max sequence length, 20)\n",
    "    \"\"\"\n",
    "    # Ensure input is a list\n",
    "    if isinstance(sequences, str):\n",
    "        singular = True\n",
    "        sequences = [sequences]\n",
    "    else:\n",
    "        singular = False\n",
    "\n",
    "    # Determine maximum sequence length and apply padding\n",
    "    max_sequence_length = max(len(sequence) for sequence in sequences)\n",
    "    padded_length = max_sequence_length\n",
    "\n",
    "    n_sequences = len(sequences)\n",
    "    blosum_size = 20  # BLOSUM62 matrix has 20 standard amino acids\n",
    "\n",
    "    # Initialize output tensor with zeros\n",
    "    tensor = torch.zeros((n_sequences, padded_length, blosum_size))\n",
    "\n",
    "    # Encode each sequence\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j, aa in enumerate(sequence):\n",
    "            if j >= padded_length:\n",
    "                break\n",
    "            # complete the code\n",
    "\n",
    "    # Squeeze output for single sequence input\n",
    "    if singular:\n",
    "        tensor = tensor.squeeze(0)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "# Define BLOSUM62 matrix\n",
    "BLOSUM62 = {\n",
    "    'A': [ 4, -1, -2, -2,  0, -1, -1,  0, -2, -1, -1, -1, -1, -2, -1,  1,  0,  0, -3, -2],\n",
    "    'R': [-1,  5,  0, -2, -3,  1,  0, -2,  0, -3, -2,  2, -1, -3, -2, -1, -1, -1, -3, -2],\n",
    "    'N': [-2,  0,  6,  1, -3,  0,  0,  0,  1, -3, -3,  0, -2, -3, -2,  1,  0, -1, -4, -2],\n",
    "    'D': [-2, -2,  1,  6, -3,  0,  2, -1, -1, -3, -4, -1, -3, -3, -1,  0, -1, -1, -4, -3],\n",
    "    'C': [ 0, -3, -3, -3,  9, -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -2],\n",
    "    'Q': [-1,  1,  0,  0, -3,  5,  2, -2,  0, -3, -2,  1,  0, -3, -1,  0, -1, -1, -2, -2],\n",
    "    'E': [-1,  0,  0,  2, -4,  2,  5, -2,  0, -3, -3,  1, -2, -3, -1,  0, -1, -1, -3, -2],\n",
    "    'G': [ 0, -2,  0, -1, -3, -2, -2,  6, -2, -4, -4, -2, -3, -3, -2,  0, -2, -2, -3, -3],\n",
    "    'H': [-2,  0,  1, -1, -3,  0,  0, -2,  8, -3, -3, -1, -2, -1, -2, -1, -2, -2,  2, -3],\n",
    "    'I': [-1, -3, -3, -3, -1, -3, -3, -4, -3,  4,  2, -3,  1,  0, -3, -2, -1, -1, -3,  3],\n",
    "    'L': [-1, -2, -3, -4, -1, -2, -3, -4, -3,  2,  4, -2,  2,  0, -3, -3, -1, -1, -2,  1],\n",
    "    'K': [-1,  2,  0, -1, -3,  1,  1, -2, -1, -3, -2,  5, -1, -3, -1,  0, -1, -1, -3, -2],\n",
    "    'M': [-1, -1, -2, -3, -1,  0, -2, -3, -2,  1,  2, -1,  5,  0, -2, -2, -1, -1, -1,  1],\n",
    "    'F': [-2, -3, -3, -3, -2, -3, -3, -3, -1,  0,  0, -3,  0,  6, -4, -2, -2, -2,  1,  3],\n",
    "    'P': [-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4,  7, -1, -1, -2, -4, -3],\n",
    "    'S': [ 1, -1,  1,  0, -1,  0,  0,  0, -1, -2, -3,  0, -2, -2, -1,  4,  1,  0, -3, -2],\n",
    "    'T': [ 0, -1,  0, -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1,  1,  5,  0, -2, -2],\n",
    "    'W': [-3, -3, -4, -4, -2, -2, -3, -3,  2, -3, -2, -3, -1,  1, -4, -3, -2, 11,  2, -3],\n",
    "    'Y': [-2, -2, -2, -3, -2, -2, -2, -3, -3,  3,  1, -2, -1,  3, -3, -2, -2,  2,  7, -1],\n",
    "    'V': [ 0, -3, -3, -3, -1, -2, -2, -3, -3,  3,  1, -2,  1,  3, -3, -2, -2, -3, -1,  4],\n",
    "}\n",
    "\n",
    "# Ensure all vectors have the same length (BLOSUM62 matrix size)\n",
    "blosum_size = len(next(iter(BLOSUM62.values())))\n",
    "\n",
    "# Add a \"padding\" token vector (zero vector)\n",
    "BLOSUM62['PAD'] = [0] * blosum_size\n",
    "\n",
    "# Function definition\n",
    "def blosum_62_encoder(sequences):\n",
    "    \"\"\"\n",
    "    Encodes sequences using BLOSUM62 matrix.\n",
    "\n",
    "    Parameters:\n",
    "        sequences (list or str): List of amino acid sequences or a single sequence.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: BLOSUM62 encoded tensor of shape\n",
    "                      (number of sequences, padding or max sequence length, 20)\n",
    "    \"\"\"\n",
    "    # Ensure input is a list\n",
    "    if isinstance(sequences, str):\n",
    "        singular = True\n",
    "        sequences = [sequences]\n",
    "    else:\n",
    "        singular = False\n",
    "\n",
    "    # Determine maximum sequence length and apply padding\n",
    "    max_sequence_length = max(len(sequence) for sequence in sequences)\n",
    "    padded_length = max_sequence_length\n",
    "\n",
    "    n_sequences = len(sequences)\n",
    "\n",
    "    # Initialize output tensor with zeros\n",
    "    tensor = torch.zeros((n_sequences, padded_length, blosum_size))\n",
    "\n",
    "    # Encode each sequence\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j, aa in enumerate(sequence):\n",
    "            if j >= padded_length:\n",
    "                break\n",
    "            # Map amino acid to BLOSUM62 encoding vector\n",
    "            tensor[i, j] = torch.tensor(BLOSUM62.get(aa, BLOSUM62['PAD']), dtype=torch.float32)\n",
    "\n",
    "    # Squeeze output for single sequence input\n",
    "    if singular:\n",
    "        tensor = tensor.squeeze(0)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def visualize_representation(representation):\n",
    "    \"\"\"\n",
    "    Visualize different representations as heat maps.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Plot the representation\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(representation.T, cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.xlabel(\"Sequence position\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.colorbar(label=\"Feature value\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5541945",
   "metadata": {},
   "source": [
    "**Task**: Visualize different representations of the dummy sequence \"SEQVENCE\" using the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349153b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = \"SEQVENCE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6829e5c3",
   "metadata": {},
   "source": [
    "## Computing distances\n",
    "\n",
    "How similar are different residues to each other using different encoding methods? Which trends can you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(rep1, rep2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two representations.\n",
    "\n",
    "    Parameters:\n",
    "        rep1 (torch.Tensor): First representation tensor.\n",
    "        rep2 (torch.Tensor): Second representation tensor.\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity between the two representations.\n",
    "    \"\"\"\n",
    "    # Flatten representations\n",
    "    rep1 = rep1.flatten()\n",
    "    rep2 = rep2.flatten()\n",
    "\n",
    "    # Calculate the dot product\n",
    "    dot_product = torch.sum(rep1 * rep2, dim=-1)\n",
    "\n",
    "    # Calculate the magnitudes\n",
    "    magnitude1 = torch.norm(rep1, dim=-1)\n",
    "    magnitude2 = torch.norm(rep2, dim=-1)\n",
    "\n",
    "    # Calculate the cosine similarity\n",
    "    similarity = dot_product / (magnitude1 * magnitude2)\n",
    "    return similarity.item()\n",
    "\n",
    "def compute_similarity_matrix(encoder, seq):\n",
    "    \"\"\"\n",
    "    Compute a similarity matrix for a given encoder and sequence.\n",
    "\n",
    "    Parameters:\n",
    "        encoder (function): Function to encode residues.\n",
    "        seq (str): Sequence of residues.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Similarity matrix.\n",
    "    \"\"\"\n",
    "    num_residues = len(seq)\n",
    "    similarity_matrix = np.zeros((num_residues, num_residues))\n",
    "    \n",
    "    # Encode all residues\n",
    "    encoded_representations = [encoder(res) for res in seq]\n",
    "    \n",
    "    # Compute pairwise cosine similarities\n",
    "    for i in range(num_residues):\n",
    "        for j in range(num_residues):\n",
    "            similarity_matrix[i, j] = cosine_similarity(\n",
    "                encoded_representations[i], encoded_representations[j]\n",
    "            )\n",
    "    return similarity_matrix\n",
    "\n",
    "def plot_heatmap(similarity_matrix, title, labels):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of the similarity matrix.\n",
    "\n",
    "    Parameters:\n",
    "        similarity_matrix (np.ndarray): Similarity matrix to plot.\n",
    "        title (str): Title of the heatmap.\n",
    "        labels (list): Labels for the heatmap axes.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(similarity_matrix, annot=False, cmap='coolwarm', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Residues\")\n",
    "    plt.ylabel(\"Residues\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "seq = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "labels = list(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4210413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d67fc7",
   "metadata": {},
   "source": [
    "**Task**: Can you change the order of the sequence below, such that similar residues will cluster together in the heatmap?\n",
    "\n",
    "Tip: Use the compute_residue_similarty function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "\n",
    "def compute_residue_similarity(encoder, res1, res2):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two residues, given a specific encoder.\n",
    "    \"\"\"\n",
    "    rep1 = encoder(res1)\n",
    "    rep2 = encoder(res2)\n",
    "    return cosine_similarity(rep1, rep2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d288d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c875a",
   "metadata": {},
   "source": [
    "## Classifying data using classical representations other than OHE\n",
    "\n",
    "**Task**: Build a classification model using a different classical representation than OHE. Take the snake venom exercise as reference if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47725219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the sequences based on the VHSE encoding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Manual padding function\n",
    "def pad_and_flatten(sequences):\n",
    "    \"\"\"\n",
    "    Pad sequences to the same length and flatten them\n",
    "    \"\"\"\n",
    "    max_len = max(seq.shape[0] for seq in sequences)\n",
    "\n",
    "    # padd sequences\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        pad_size = max_len - seq.shape[0]\n",
    "        padded_seq = np.pad(seq, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)\n",
    "        flattened_seq = padded_seq.reshape(-1)\n",
    "        padded_sequences.append(flattened_seq)\n",
    "\n",
    "    return np.array(padded_sequences)\n",
    "\n",
    "# Load X and y from df\n",
    "X = df['Sequence']\n",
    "y = df['Function Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178fa30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2951f79",
   "metadata": {},
   "source": [
    "# Latent variable models\n",
    "\n",
    "This is the part we have been all waiting for (drummroll), we are now going to build an representation learning model for protein sequences! (yay?)\n",
    "\n",
    "Use the following guidelines (and especially the Autoencoder notebook) for guidance:\n",
    "\n",
    "1. pick a classical representation of your choice (OHE, VHSE, BLOSUM62) as your initial representation method.\n",
    "2. Study the simple autoencoder model architecture and training loop below, that I here train on OHE sequences. Try another representation if you feel adventurous\n",
    "3. Expand the model architecture to encompass some more interesting convolutional layers.\n",
    "    a. Play around with the filter sizes and strides and channels.\n",
    "    b. Add some more filters\n",
    "4. Turn the autoencoder into a VAE (Tip: create a new class for the VAE, so you can compare the generative capabilities better after training both)\n",
    "5. Once you have a model that you are satisfied with use more data.\n",
    "6. Visualize the representations of your trained model.\n",
    "7. **Optional**: Train a classification model using your representations\n",
    "8. **Bonus exercise 1 for advanced ML enjoyer** s: Think of ways to sample specific venom classes from your trained VAE? \n",
    "    a. Tip: You could try to use generative models to sample from specific regions in latent space.\n",
    "9. **Bonus exercise 2 for snake enjoyers** : Write a story about your favourite snake and send it to me and Tim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ProteinAutoencoder(nn.Module):\n",
    "    def __init__(self, num_filters=32, latent_dim=64, sequence_length=50):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_filters (int): Number of filters in the convolutional layers.\n",
    "            latent_dim (int): Size of the latent representation.\n",
    "            sequence_length (int): Length of the input sequence (N).\n",
    "        \"\"\"\n",
    "        super(ProteinAutoencoder, self).__init__()\n",
    "        \n",
    "        # Compute the flattened size after Conv2d\n",
    "        conv_output_size = sequence_length * num_filters\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(1, 20)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),  # Flattens to (batch_size, sequence_length * num_filters)\n",
    "            nn.Linear(conv_output_size, latent_dim)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, conv_output_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (num_filters, sequence_length, 1)),  # Reshapes to (batch_size, num_filters, sequence_length, 1)\n",
    "            nn.ConvTranspose2d(in_channels=num_filters, out_channels=1, kernel_size=(1, 20))\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the autoencoder.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 1, N, 20).\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed input of shape (batch_size, 1, N, 20).\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return torch.sigmoid(x)  # Bound output to [0, 1]\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encode input data.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 1, N, 20).\n",
    "        Returns:\n",
    "            torch.Tensor: Encoded representation of shape (batch_size, latent_dim).\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def generate(self, x):\n",
    "        \"\"\"\n",
    "        Generate output data.\n",
    "        Args:\n",
    "            x (torch.Tensor): Encoded tensor of shape (batch_size, latent_dim).\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed input of shape (batch_size, 1, N, 20).\n",
    "        \"\"\"\n",
    "        x = self.decoder(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97774116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect sequences from the dataset below length 50\n",
    "short_sequences = df[df['Sequence'].str.len() < 50]['Sequence'].values\n",
    "\n",
    "# one-hot encode the sequences\n",
    "short_sequences_ohe = [one_hot_encode(seq) for seq in short_sequences]\n",
    "\n",
    "# pad the sequences to the same length\n",
    "padd_length = 50\n",
    "short_sequences_ohe_padded = [F.pad(seq, (0, 0, 0, padd_length - seq.size(0))) for seq in short_sequences_ohe]\n",
    "\n",
    "# create dataset and data loader\n",
    "batch_size = 32\n",
    "short_sequences_dataset = torch.stack(short_sequences_ohe_padded)\n",
    "short_sequences_loader = DataLoader(short_sequences_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = ProteinAutoencoder(num_filters=32, latent_dim=16)\n",
    "print(model)\n",
    "\n",
    "# simple training loop\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in short_sequences_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch.unsqueeze(1).float())\n",
    "        loss = criterion(outputs, batch.unsqueeze(1).float())\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
